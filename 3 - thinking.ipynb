{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5yiH5h8x3h"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# Introduction to Gemini 2.0 Flash Thinking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4Ti6Q0QKIl"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/gemini-2/thinking.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w14yjWnPVD-"
      },
      "source": [
        "[Gemini 2.0 Flash Thinking](https://ai.google.dev/gemini-api/docs/thinking-mode), is an experimental model that explicitly showcases its thoughts. Built on the speed and performance of Gemini 2.0 Flash, this model is trained to use thoughts in a way that leads to stronger reasoning capabilities.\n",
        "\n",
        "You'll see examples of those reasoning capabilities with [code understanding](#scrollTo=GAa7sCD7tuMW), [geometry](#scrollTo=ADiJV-fFyjRe) and [math](#scrollTo=EXPPWpt6ttJZ) problems and for [generating questions](#scrollTo=dtBDPf4kAyG1) adapted to a specific level of knowledge.\n",
        "\n",
        "As you will see, the model is exposing its thoughts so you can have a look at its reasoning and how it did reach its conclusions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0HWzIEAQYqz"
      },
      "source": [
        "## 0/ Setup\n",
        "\n",
        "This section install the SDK, set it up using your [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n",
        "\n",
        "Just collapse (click on the little arrow on the left of the title) and run this section if you want to jump straight to the examples (just don't forget to run it otherwise nothing will work)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzBKAaL4QYq0"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both. This means that you can prototype an application using the Developer API and then migrate the application to Vertex AI without rewriting your code.\n",
        "\n",
        "More details about this new SDK on the [documentation](https://ai.google.dev/gemini-api/docs/sdks) or in the [Getting started](../gemini-2/get_started.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-genai>=0.3.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDUGen_kQYq2"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Lez1vBQYq3"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://link_to_vertex_AI)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgsQyaXQYq4"
      },
      "source": [
        "### Check the \"thinking\" model info\n",
        "\n",
        "The [Gemini 2.0 Flash Thinking](https://ai.google.dev/gemini-api/docs/thinking-mode) model is optimized for complex tasks that need multiple rounds of strategyzing and iteratively solving.\n",
        "\n",
        "For more information about all Gemini models, check the [documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for extended information on each of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "pprint(client.models.get(model=\"gemini-2.0-flash-thinking-exp\").model_dump(exclude_defaults=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAPiYdYMfeJP"
      },
      "source": [
        "# 1/ Examples\n",
        "\n",
        "Here are some quite complex examples of what Gemini 2.0 thinking model can solve.\n",
        "\n",
        "In each of them you can select different models to see how this new model compares to its predecesors.\n",
        "\n",
        "In some cases, you'll still get the good answer from the other models, in that case, re-run it a couple of times and you'll see that Gemini 2.0 thinking is more consistent thanks to its thinking step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAa7sCD7tuMW"
      },
      "source": [
        "## Example #1: code simplification\n",
        "\n",
        "First, try with a simple code comprehension and simplification example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PZw41-lsKKMf"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-thinking-exp\",\n",
        "    contents='How can I simplify this? `(Math.round(radius/pixelsPerMile * 10) / 10).toFixed(1);`'\n",
        ")\n",
        "\n",
        "pprint(response.candidates[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLsI2hSYdkP"
      },
      "source": [
        "As you can see, your response has multiple parts. While you could use `response.text` to get all of it right away as usual it's actually more interesting to check each of them separately when using the thinking model.\n",
        "\n",
        "The first part is the \"inner thoughts\" of the model, that where it analyzes the problem and comes up with its strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cXZocSREYP4L"
      },
      "outputs": [],
      "source": [
        "# First part is the inner thoughts of the model\n",
        "Markdown(response.candidates[0].content.parts[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyEcABkgY_0m"
      },
      "source": [
        "Most of the time you won't need to checks the thoughts as you'll be mostly interested in the answer, but having access to them gives you a way to check where the answers comes from and how the model came up with it. It's not a black box anymore!\n",
        "\n",
        "If you are using the `v1alpha` API, you'll see a `thought=True`, indicating that the first part is indeed thoughts.\n",
        "\n",
        "Then the second part is the actual answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JSImDxnhZGmB"
      },
      "outputs": [],
      "source": [
        "# Second part is the response from the model\n",
        "Markdown(response.candidates[0].content.parts[1].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL1Zrx9UZaxh"
      },
      "source": [
        "As a comparison here's what you'd get with the \"classic\" [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) model.\n",
        "\n",
        "Unlike thinking mode, the normal model does not articulates its thoughts and tries to answer right away which can lead to more simpler answers to complex problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbDUeZqzYIrU"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents='How can I simplify this? `(Math.round(radius/pixelsPerMile * 10) / 10).toFixed(1);`'\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADiJV-fFyjRe"
      },
      "source": [
        "## Example #2: Geometry problem (with image)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using Gemini multimodal abilities to read the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MIcXWXqyzCjQ"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/geometry.png -O geometry.png -q\n",
        "\n",
        "im = Image.open(\"geometry.png\").resize((256,256))\n",
        "im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Lb9o7AeDwVyZ"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.0-flash-thinking-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash\",\"gemini-1.5-pro\",\"gemini-2.0-flash-exp\", \"gemini-2.0-flash-thinking-exp\"] {\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        im,\n",
        "        \"What's the area of the overlapping region?\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(Markdown(\"## Thoughts\"))\n",
        "display(Markdown(response.candidates[0].content.parts[0].text))\n",
        "display(Markdown(\"## Answer\"))\n",
        "display(Markdown(response.candidates[0].content.parts[1].text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXPPWpt6ttJZ"
      },
      "source": [
        "## Example #3: Brain teaser with a twist\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the toughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "F2YeBqzC0J_i"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/pool.png -O pool.png -q\n",
        "\n",
        "im = Image.open(\"pool.png\")\n",
        "im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Vt2dSjeqA9ZC"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.0-flash-thinking-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash\",\"gemini-1.5-pro\",\"gemini-2.0-flash-exp\", \"gemini-2.0-flash-thinking-exp\"] {\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        im,\n",
        "        \"How do I use three of these numbers to sum up to 30?\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(Markdown(\"## Thoughts\"))\n",
        "display(Markdown(response.candidates[0].content.parts[0].text))\n",
        "display(Markdown(\"## Answer\"))\n",
        "display(Markdown(response.candidates[0].content.parts[1].text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtBDPf4kAyG1"
      },
      "source": [
        "## Example #4: Generating question for a specific level of knowledge\n",
        "\n",
        "This time, the questions requires a few types of knowledge, including what is relevant to the Physics C exam. The questions generated are not the interesting part, but the reasoning to come up with them shows they are not just randomly generated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0mjH0A8HBQ5d"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.0-flash-thinking-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash\",\"gemini-1.5-pro\",\"gemini-2.0-flash-exp\", \"gemini-2.0-flash-thinking-exp\"] {\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=\"Give me a practice question I can use for the AP Physics C exam?\"\n",
        ")\n",
        "\n",
        "display(Markdown(\"## Thoughts\"))\n",
        "display(Markdown(response.candidates[0].content.parts[0].text))\n",
        "display(Markdown(\"## Answer\"))\n",
        "display(Markdown(response.candidates[0].content.parts[1].text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lND4jB6MrsSk"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "Try the [Gemini 2.0 Flash Thinking](https://aistudio.google.com/app/prompts/new_chat?model=gemini-2.0-flash-thinking-exp) model in AI Studio with all your crazy problems and brain teasers.\n",
        "\n",
        "For more examples of the Gemini 2.0 capabilities, check the [Gemini 2.0 folder of the cookbook](https://github.com/google-gemini/cookbook/blob/main/gemini-2/). You'll learn how to use the [Live API](live_api_starter.ipynb), juggle with [multiple tools](./plotting_and_mapping.ipynb) or use Gemini 2.0 [spatial understanding](./spatial_understanding.ipynb) abilities."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "R0HWzIEAQYqz"
      ],
      "name": "thinking.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
