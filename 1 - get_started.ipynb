{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtVOlmDSHmh4"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9r9Ggw012g9c"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVmFDcYOSNiV"
      },
      "source": [
        "# Gemini API: Getting started with Gemini 2.0\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/gemini-2/get_started.ipynb\"><img src=\"https://ai.google.dev/site-assets/images/docs/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrWvVAIP3c1v"
      },
      "source": [
        "The new **[Google Gen AI SDK](https://github.com/googleapis/python-genai)** provides a unified interface to [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) through both the [Gemini Developer API](https://ai.google.dev/gemini-api/docs) and the Gemini API on [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview). With a few exceptions, code that runs on one platform will run on both. This notebook uses the Developer API.\n",
        "\n",
        "This notebook will walk you through:\n",
        "\n",
        "* [Installing and setting-up](get_started.ipynb#scrollTo=Mfk6YY3G5kqp) the Google GenAI SDK\n",
        "* [Text](get_started.ipynb#scrollTo=6TYNPrNvQ8ue) and [multimodal](#scrollTo=yww-vrxmRiIy) prompting\n",
        "* Counting [tokens](get_started.ipynb#scrollTo=_9B8pb7tv_Cx)\n",
        "* Setting system instructions\n",
        "* Configuring [safety filters](get_started.ipynb#scrollTo=HTAnYx_bbxPk)\n",
        "* Initiating a [multi-turn chat](get_started.ipynb#scrollTo=HTAnYx_bbxPk)\n",
        "* [Controlling generated output](get_started.ipynb#scrollTo=nyZMoM6tgnTA)\n",
        "* Using [function calling](get_started.ipynb#scrollTo=Rl-y9SZywD0s)\n",
        "* Generating a [content stream](get_started.ipynb#scrollTo=uQfLCxfQtPTg) and sending [asynchronous](#scrollTo=plCtEIaHuv96) requests\n",
        "* Using [file uploads](get_started.ipynb#scrollTo=enBhuaIk3KYa)\n",
        "* Using [context caching](get_started.ipynb#scrollTo=oTgeR3_9wN5J)\n",
        "* Generating [text embeddings](get_started.ipynb#scrollTo=sXNCRn8Wx71d)\n",
        "\n",
        "More details about this new SDK on the [documentation](https://ai.google.dev/gemini-api/docs/sdks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfk6YY3G5kqp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5027929de8f"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "Install the SDK from [PyPI](https://github.com/googleapis/python-genai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46zEFO2a9FFd"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTIfnvCn9HvH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1pkoyZb9Jm3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hx_Gw9i0Yuv"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HghvVpbU0Uap"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvA_mbi1JxD5"
      },
      "source": [
        "### Choose a model\n",
        "\n",
        "This notebook will teach you how to use the [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) model with the GenAI SDK. But the SDK also work with the 1.5 generation of models.\n",
        "\n",
        "For more information about all Gemini models, check the [documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for extended information on each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AChpZWIXu62m"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash-002\",\"gemini-1.5-pro-002\",\"gemini-2.0-flash-exp\"] {\"allow-input\":true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TYNPrNvQ8ue"
      },
      "source": [
        "## Send text prompts\n",
        "\n",
        "Use the `generate_content` method to generate responses to your prompts. You can pass text directly to `generate_content`, and use the `.text` property to get the text content of the response. Note that the `.text` field will work when there's only one part in the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8md0ayAJ-RZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9B8pb7tv_Cx"
      },
      "source": [
        "## Count tokens\n",
        "\n",
        "You can use the `count_tokens` method to calculate the number of input tokens before sending a request to the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7WFm928wEYR"
      },
      "outputs": [],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yww-vrxmRiIy"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Use Gemini 2.0 model (`gemini-2.0-flash-exp`), a multimodal model that supports multimodal prompts. You can include text, [PDF documents](../quickstarts/PDF_Files.ipynb), images, [audio](../quickstarts/Audio.ipynb) and [video](../quickstarts/Video.ipynb) in your prompt requests and get text or code responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ3zu5udSBuD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "\n",
        "IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\" # @param {type: \"string\"}\n",
        "\n",
        "img_bytes = requests.get(IMG).content\n",
        "\n",
        "img_path = pathlib.Path('jetpack.png')\n",
        "img_path.write_bytes(img_bytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDxd7Pp_SELb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "image = Image.open(img_path)\n",
        "image.thumbnail([512,512])\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        image,\n",
        "        \"Write a short and engaging blog post based on this picture.\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(image)\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTzuBfHyWAg5"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. Learn more about [experimenting with parameter values](https://ai.google.dev/gemini-api/docs/text-generation?lang=node#configure)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5izy6jsbEnL"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.4,\n",
        "        top_p=0.95,\n",
        "        top_k=20,\n",
        "        candidate_count=1,\n",
        "        seed=5,\n",
        "        max_output_tokens=100,\n",
        "        stop_sequences=[\"STOP!\"],\n",
        "        presence_penalty=0.0,\n",
        "        frequency_penalty=0.0,\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTAnYx_bbxPk"
      },
      "source": [
        "## Configure safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://ai.google.dev/gemini-api/docs/safety-settings) page for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJIvAfMqbzQL"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "    Write a list of 2 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        safety_settings=safety_settings,\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6sB7W-jdGxJ"
      },
      "source": [
        "## Start a multi-turn chat\n",
        "\n",
        "The Gemini API enables you to have freeform conversations across multiple turns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIC0pLnJdI8m"
      },
      "outputs": [],
      "source": [
        "system_instruction=\"\"\"\n",
        "  You are an expert software developer and a helpful coding assistant.\n",
        "  You are able to generate high-quality code in any programming language.\n",
        "\"\"\"\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        temperature=0.5,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVQZitGE7EbW"
      },
      "source": [
        "Use `chat.send_message` to pass a message back and receive a response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnzMJJ-adOfX"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qAObeZMdgln"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Okay, write a unit test of the generated function.\")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyZMoM6tgnTA"
      },
      "source": [
        "## Generate JSON\n",
        "\n",
        "The [controlled generation](https://ai.google.dev/gemini-api/docs/structured-output?lang=python#generate-json) capability in Gemini API allows you to constraint the model output to a structured format. You can provide the schemas as Pydantic Models or a JSON string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRJHVjr-gqHi"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    recipe_name: str\n",
        "    recipe_description: str\n",
        "    recipe_ingredients: list[str]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Provide a popular cookie recipe and its ingredients.\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "    ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfLCxfQtPTg"
      },
      "source": [
        "## Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gIsSNqXtOXB"
      },
      "outputs": [],
      "source": [
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\"\n",
        "):\n",
        "  print(chunk.text)\n",
        "  print(\"*****************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plCtEIaHuv96"
      },
      "source": [
        "## Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all the analogous async methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPTI7noYuwgr"
      },
      "outputs": [],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl-y9SZywD0s"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function calling](https://ai.google.dev/gemini-api/docs/function-calling) lets you provide a set of tools that it can use to respond to the user's prompt. You create a description of a function in your code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APk6sXO6wLQp"
      },
      "outputs": [],
      "source": [
        "get_destination = types.FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = types.Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "        ),\n",
        ")\n",
        "\n",
        "response.candidates[0].content.parts[0].function_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enBhuaIk3KYa"
      },
      "source": [
        "## Upload files\n",
        "\n",
        "Now that you've seen how to send multimodal prompts, try uploading files to the API of different multimedia types. For small images, such as the previous multimodal example, you can point the Gemini model directly to a local file when providing a prompt. When you have larger files, many files, or files you don't want to send over and over again, you can use the File Upload API, and then pass the file by reference.\n",
        "\n",
        "For larger text files, images, videos, and audio, upload the files with the File API before including them in prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGswPFKrTvby"
      },
      "source": [
        "### Upload an image file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FVVJHb828le"
      },
      "outputs": [],
      "source": [
        "# Prepare the file to be uploaded\n",
        "IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\"  # @param {type: \"string\"}\n",
        "img_bytes = requests.get(IMG).content\n",
        "\n",
        "img_path = pathlib.Path('jetpack.png')\n",
        "img_path.write_bytes(img_bytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlJ9NwRGT6d1"
      },
      "outputs": [],
      "source": [
        "# Upload the file using the API\n",
        "file_upload = client.files.upload(path=img_path)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1y5eZmqThDR"
      },
      "source": [
        "### Upload text file\n",
        "\n",
        "Let's start by uploading a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sa6lEH9Tjm5"
      },
      "outputs": [],
      "source": [
        "# Prepare the file to be uploaded\n",
        "TEXT = \"https://storage.googleapis.com/generativeai-downloads/data/a11.txt\"  # @param {type: \"string\"}\n",
        "text_bytes = requests.get(TEXT).content\n",
        "\n",
        "text_path = pathlib.Path('a11.txt')\n",
        "text_path.write_bytes(text_bytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC3bJQJcUKFk"
      },
      "outputs": [],
      "source": [
        "# Upload the file using the API\n",
        "file_upload = client.files.upload(path=text_path)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        \"Can you give me a summary of this information please?\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLV19RrMUlaw"
      },
      "source": [
        "### Upload a PDF file\n",
        "\n",
        "This PDF page is an article titled [Smoothly editing material properties of objects](https://research.google/blog/smoothly-editing-material-properties-of-objects-with-text-to-image-models-and-synthetic-data/) with text-to-image models and synthetic data available on the Google Research Blog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0BfhLDFWfCS"
      },
      "outputs": [],
      "source": [
        "# Prepare the file to be uploaded\n",
        "PDF = \"https://storage.googleapis.com/generativeai-downloads/data/Smoothly%20editing%20material%20properties%20of%20objects%20with%20text-to-image%20models%20and%20synthetic%20data.pdf\"  # @param {type: \"string\"}\n",
        "pdf_bytes = requests.get(PDF).content\n",
        "\n",
        "pdf_path = pathlib.Path('article.pdf')\n",
        "pdf_path.write_bytes(pdf_bytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH2h2WDVWptt"
      },
      "outputs": [],
      "source": [
        "# Upload the file using the API\n",
        "file_upload = client.files.upload(path=pdf_path)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        \"Can you summarize this file as a bulleted list?\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NWO1moe9fx-"
      },
      "source": [
        "### Upload an audio file\n",
        "\n",
        "In this case, you'll use a [sound recording](https://www.jfklibrary.org/asset-viewer/archives/jfkwha-006) of President John F. Kennedy’s 1961 State of the Union address."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCSuGd9i9fEB"
      },
      "outputs": [],
      "source": [
        "# Prepare the file to be uploaded\n",
        "AUDIO = \"https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3\"  # @param {type: \"string\"}\n",
        "audio_bytes = requests.get(AUDIO).content\n",
        "\n",
        "audio_path = pathlib.Path('audio.mp3')\n",
        "audio_path.write_bytes(audio_bytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wjKO0eI9yps"
      },
      "outputs": [],
      "source": [
        "# Upload the file using the API\n",
        "file_upload = client.files.upload(path=audio_path)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        \"Listen carefully to the following audio file. Provide a brief summary\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdUjkIQP-G_i"
      },
      "source": [
        "### Upload a video file\n",
        "\n",
        "In this case, you'll use a short clip of [Big Buck Bunny](https://peach.blender.org/about/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9ohtLxU-SFE"
      },
      "outputs": [],
      "source": [
        "# Download the video file\n",
        "VIDEO_URL = \"https://download.blender.org/peach/bigbuckbunny_movies/BigBuckBunny_320x180.mp4\"  # @param {type: \"string\"}\n",
        "video_file_name = \"BigBuckBunny_320x180.mp4\"\n",
        "!wget -O {video_file_name} $VIDEO_URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyFVXPspS5GF"
      },
      "source": [
        "Let's start by uploading the video file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY1WlxMk-0Uy"
      },
      "outputs": [],
      "source": [
        "video_file = client.files.upload(path=video_file_name)\n",
        "print(f\"Completed upload: {video_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yRG9BPXS65b"
      },
      "source": [
        "The state of the video is important. The video must finish processing, so do check the state. Once the state of the video is `ACTIVE`, you are able to pass it into `generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEk4P3fK_OcJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Prepare the file to be uploaded\n",
        "while video_file.state == \"PROCESSING\":\n",
        "    print('Waiting for video to be processed.')\n",
        "    time.sleep(10)\n",
        "    video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "if video_file.state == \"FAILED\":\n",
        "  raise ValueError(video_file.state)\n",
        "print(f'Video processing complete: ' + video_file.uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMz9GIuvAiCO"
      },
      "outputs": [],
      "source": [
        "print(video_file.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX82TyGL-e2O"
      },
      "outputs": [],
      "source": [
        "# Upload the file using the API\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=video_file.uri,\n",
        "                    mime_type=video_file.mime_type),\n",
        "                ]),\n",
        "        \"Describe this video.\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTgeR3_9wN5J"
      },
      "source": [
        "## Use context caching\n",
        "\n",
        "[Context caching](https://ai.google.dev/gemini-api/docs/caching?lang=python) lets you to store frequently used input tokens in a dedicated cache and reference them for subsequent requests, eliminating the need to repeatedly pass the same set of tokens to a model.\n",
        "\n",
        "Context caching is only available for stable models with fixed versions (for example, `gemini-1.5-pro-002`). You must include the version postfix (for example, the `-002` in `gemini-1.5-pro-002`). It is not yet available of Gemini 2.0 because it is an experimental model. You can find more caching examples [here](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgl2gzmuwQXz"
      },
      "source": [
        "#### Create a cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Jb0gaiwOVi"
      },
      "outputs": [],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are an expert researcher who has years of experience in conducting systematic literature surveys and meta-analyses of different topics.\n",
        "  You pride yourself on incredible accuracy and attention to detail. You always stick to the facts in the sources provided, and never make up new facts.\n",
        "  Now look at the research paper below, and answer the following questions in 1-2 sentences.\n",
        "\"\"\"\n",
        "\n",
        "urls = [\n",
        "    'https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrylX7r3w2bF"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import mimetypes\n",
        "import pathlib\n",
        "\n",
        "uploads = []\n",
        "for url in urls:\n",
        "  mime_type,_ = mimetypes.guess_type(url)\n",
        "  file_bytes = requests.get(url).content\n",
        "  name = pathlib.Path(url).name\n",
        "  pathlib.Path(name).write_bytes(file_bytes)\n",
        "  uploads.append(client.files.upload(path=name, config=dict(mime_type=mime_type)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_I-OC6xw6HF"
      },
      "outputs": [],
      "source": [
        "pdf_parts = [\n",
        "    types.Part.from_uri(f.uri, mime_type=f.mime_type)\n",
        "    for f in uploads\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MBsaipow7m5"
      },
      "outputs": [],
      "source": [
        "cached_content = client.caches.create(\n",
        "      model=\"gemini-1.5-pro-002\",\n",
        "      contents=[\n",
        "          \"Hey, can you summarize these docs?\",\n",
        "          types.Content(\n",
        "              role=\"user\",\n",
        "              parts=pdf_parts,\n",
        "          )],\n",
        "      config=types.CreateCachedContentConfig(\n",
        "          system_instruction=system_instruction,\n",
        "          ttl=\"3600s\",\n",
        "      ),\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKgCRRXfwU_m"
      },
      "source": [
        "#### Use a cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qo7-sU2w92j"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=cached_content.model,\n",
        "    contents=\"What is the research goal shared by these research papers?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        cached_content=cached_content.name,\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxJ_2Bel_Kqg"
      },
      "outputs": [],
      "source": [
        "response.usage_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QSOsWurx4CG"
      },
      "source": [
        "#### Delete a cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSZeG60Dx4V-"
      },
      "outputs": [],
      "source": [
        "client.caches.delete(name=cached_content.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXNCRn8Wx71d"
      },
      "source": [
        "## Get text embeddings\n",
        "\n",
        "You can get text embeddings for a snippet of text by using `embed_content` method. All models produce an output with 768 dimensions by default. However, some models give users the option to choose an output dimensionality between 1 and 768. See the [embeddings guide](https://ai.google.dev/gemini-api/docs/embeddings) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpJIA5zmx8Vy"
      },
      "outputs": [],
      "source": [
        "TEXT_EMBEDDING_MODEL_ID = \"text-embedding-004\" # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0afi69R9x_bh"
      },
      "outputs": [],
      "source": [
        "response = client.models.embed_content(\n",
        "    model=TEXT_EMBEDDING_MODEL_ID,\n",
        "    contents=[\n",
        "        \"How do I get a driver's license/learner's permit?\",\n",
        "        \"How do I renew my driver's license?\",\n",
        "        \"How do I change my address on my driver's license?\"\n",
        "        ],\n",
        "    config=types.EmbedContentConfig(output_dimensionality=128)\n",
        ")\n",
        "\n",
        "print(response.embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tje8pMbd5z7j"
      },
      "source": [
        "You will get a set of three embeddings, one for each piece of text you passed in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNeuBlNt4CRk"
      },
      "outputs": [],
      "source": [
        "len(response.embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5UPmq3543E"
      },
      "source": [
        "You can also see the length of each embedding is 128, as per the `output_dimensionality` you specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4oAtC8a4GYH"
      },
      "outputs": [],
      "source": [
        "len(response.embeddings[0].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search as a tool\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search. The following example shows how to configure Search as a tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "google_search_tool = Tool(\n",
        "    google_search = GoogleSearch()\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"When is the next total solar eclipse in the United States?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[google_search_tool],\n",
        "        response_modalities=[\"TEXT\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "for each in response.candidates[0].content.parts:\n",
        "    print(each.text)\n",
        "\n",
        "print(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SOkIVJIyF1W"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "### Useful API references:\n",
        "\n",
        "Check out the [Google GenAI SDK](https://github.com/googleapis/python-genai) for more details on the new SDK.\n",
        "\n",
        "### Related examples\n",
        "\n",
        "For more detailed examples using Gemini 2.0, check the [Gemini 2.0 folder of the cookbook](https://github.com/google-gemini/cookbook/blob/main/gemini-2/). You'll learn how to use the [Live API](live_api_starter.ipynb), juggle with [multiple tools](./plotting_and_mapping.ipynb) or use Gemini 2.0 [spatial understanding](./spatial_understanding.ipynb) abilities.\n",
        "\n",
        "Also check the [experimental Gemini 2.0 Flash Thinking](./thinking.ipynb) model that explicitly showcases its thoughts and can manage more complex reasonings."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
